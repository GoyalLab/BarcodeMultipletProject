{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import io\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from itertools import combinations\n",
    "import random\n",
    "import pathlib\n",
    "from count_doublets_utils import *\n",
    "np.random.seed(2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = \"/projects/p31666/zzhang/doublet-bchmk/data/fatemap_data/FM01/fatemapID/stepFourStarcodeShavedReads50.txt\"\n",
    "umi_cutoff_ratio=3 / 4e5\n",
    "umi_diff_threshold=50\n",
    "dominant_threshold=10\n",
    "num_tests=5000\n",
    "data_root = \"/projects/p31666/zzhang/doublet-bchmk/data/fatemap_data\"\n",
    "keyword = \"stepFourStarcodeShavedReads50\"\n",
    "pattern = '**/{}*'.format(keyword)\n",
    "def grab_input_files(root_dir, file_format):\n",
    "    grabbed_files = []\n",
    "    for filepath in pathlib.Path(root_dir).glob(pattern):\n",
    "        grabbed_files.append(str(filepath.absolute()))\n",
    "    return grabbed_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on if good data is correct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Testing on /projects/p31666/zzhang/doublet-bchmk/data/fatemap_data/FM04/fatemapID/stepFourStarcodeShavedReads50.txt\n",
      "Current Sample Adjusted UMI cutoff: 2\n",
      "Current Sample Adjusted UMI cutoff: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [06:28<00:00, 12.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Testing on /projects/p31666/zzhang/doublet-bchmk/data/fatemap_data/non_cancer/fatemapID/stepFourStarcodeShavedReads50.txt\n",
      "Current Sample Adjusted UMI cutoff: 4\n",
      "Current Sample Adjusted UMI cutoff: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [07:02<00:00, 11.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Testing on /projects/p31666/zzhang/doublet-bchmk/data/fatemap_data/FM05/fatemapID/stepFourStarcodeShavedReads50.txt\n",
      "Current Sample Adjusted UMI cutoff: 2\n",
      "Current Sample Adjusted UMI cutoff: 2\n",
      "Current Sample Adjusted UMI cutoff: 1\n",
      "Current Sample Adjusted UMI cutoff: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [07:26<00:00, 11.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Testing on /projects/p31666/zzhang/doublet-bchmk/data/fatemap_data/FM06/fatemapID/stepFourStarcodeShavedReads50.txt\n",
      "Current Sample Adjusted UMI cutoff: 3\n",
      "Current Sample Adjusted UMI cutoff: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [07:10<00:00, 11.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Testing on /projects/p31666/zzhang/doublet-bchmk/data/fatemap_data/FM01/fatemapID/stepFourStarcodeShavedReads50.txt\n",
      "Current Sample Adjusted UMI cutoff: 3\n",
      "Current Sample Adjusted UMI cutoff: 3\n",
      "Current Sample Adjusted UMI cutoff: 3\n",
      "Current Sample Adjusted UMI cutoff: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [13:17<00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Testing on /projects/p31666/zzhang/doublet-bchmk/data/fatemap_data/FM02/fatemapID/stepFourStarcodeShavedReads50.txt\n",
      "Current Sample Adjusted UMI cutoff: 12\n",
      "Current Sample Adjusted UMI cutoff: 15\n",
      "Current Sample Adjusted UMI cutoff: 9\n",
      "Current Sample Adjusted UMI cutoff: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [48:23<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Testing on /projects/p31666/zzhang/doublet-bchmk/data/fatemap_data/FM03/fatemapID/stepFourStarcodeShavedReads50.txt\n",
      "Current Sample Adjusted UMI cutoff: 12\n",
      "Current Sample Adjusted UMI cutoff: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [28:04<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Testing on /projects/p31666/zzhang/doublet-bchmk/data/fatemap_data/FM08/fatemapID/stepFourStarcodeShavedReads50.txt\n",
      "Current Sample Adjusted UMI cutoff: 5\n",
      "Current Sample Adjusted UMI cutoff: 11\n",
      "Current Sample Adjusted UMI cutoff: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [17:14<00:00,  4.83it/s]\n"
     ]
    }
   ],
   "source": [
    "all_fatemap_read_files = grab_input_files(data_root, pattern)\n",
    "for cur_fatemap_read_file in all_fatemap_read_files:\n",
    "    print(\"INFO: Testing on {}\".format(cur_fatemap_read_file))\n",
    "    df = pd.read_csv(cur_fatemap_read_file, sep='\\t')\n",
    "    header = list(df.columns)\n",
    "    if header[-1].lower() == \"sampleNum\".lower():\n",
    "        header[-1] = \"sampleNum\"\n",
    "        df.columns = header\n",
    "    good_data_ls = []\n",
    "    for cur_sample_num in df[\"sampleNum\"].unique():\n",
    "        cur_sample_df = df[df[\"sampleNum\"] == cur_sample_num]\n",
    "        cur_umi_adjusted_cutoff = round(umi_cutoff_ratio * cur_sample_df.shape[0])\n",
    "        print(\"Current Sample Adjusted UMI cutoff: {}\".format(cur_umi_adjusted_cutoff))\n",
    "        cur_freq_df = cur_sample_df.groupby(['cellID', 'BC50StarcodeD8', 'sampleNum']).size().reset_index()\n",
    "        cur_freq_df.columns = ['cellID', \"fatemapID\", 'sampleNum', \"nUMI\"]\n",
    "        cur_good_data = cur_freq_df[cur_freq_df['nUMI'] >= cur_umi_adjusted_cutoff].reset_index(drop=True)\n",
    "        good_data_ls.append(cur_good_data)\n",
    "\n",
    "    good_data = pd.concat(good_data_ls)\n",
    "    good_data = good_data.sort_values(by=[\"sampleNum\", 'cellID', 'fatemapID', 'nUMI']).reset_index(drop=True)\n",
    "    idx_list = random.sample(list(np.arange(good_data.shape[0])), num_tests)\n",
    "    umi_cutoff_dict = {}\n",
    "    for cur_sample_num in df[\"sampleNum\"].unique():\n",
    "        cur_sample_df = df[df[\"sampleNum\"] == cur_sample_num]\n",
    "        cur_umi_adjusted_cutoff = round(umi_cutoff_ratio * cur_sample_df.shape[0])\n",
    "        umi_cutoff_dict[cur_sample_num]=cur_umi_adjusted_cutoff\n",
    "    for idx in tqdm(idx_list):\n",
    "        cur_sample = good_data.iloc[idx][\"sampleNum\"]\n",
    "        cell_id = good_data.iloc[idx][\"cellID\"]\n",
    "        fatemap_id = good_data.iloc[idx][\"fatemapID\"]\n",
    "        cur_df = df[(df[\"cellID\"]==cell_id) & (df[\"BC50StarcodeD8\"]==fatemap_id) & (df[\"sampleNum\"]==cur_sample)]\n",
    "        correct_umi_count=cur_df.shape[0]\n",
    "        if(correct_umi_count<umi_cutoff_dict[cur_sample]):\n",
    "            continue\n",
    "        calculated_count = good_data[(good_data[\"cellID\"]==cell_id) & \\\n",
    "                                     (good_data[\"fatemapID\"]==fatemap_id) & (good_data[\"sampleNum\"]==cur_sample)][\"nUMI\"].values[0]\n",
    "        if(correct_umi_count!=calculated_count):\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on if fatemap barcode to cellID dict is produced correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tests=5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Testing on /projects/p31666/zzhang/doublet-bchmk/data/fatemap_data/FM04/fatemapID/stepFourStarcodeShavedReads50.txt\n",
      "Current Sample Adjusted UMI cutoff: 2\n",
      "Current Sample Adjusted UMI cutoff: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:09<00:00, 520.86it/s]\n",
      "100%|██████████| 5000/5000 [00:09<00:00, 539.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Testing on /projects/p31666/zzhang/doublet-bchmk/data/fatemap_data/non_cancer/fatemapID/stepFourStarcodeShavedReads50.txt\n",
      "Current Sample Adjusted UMI cutoff: 4\n",
      "Current Sample Adjusted UMI cutoff: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2766/2766 [00:07<00:00, 380.94it/s]\n",
      "100%|██████████| 2794/2794 [00:07<00:00, 381.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Testing on /projects/p31666/zzhang/doublet-bchmk/data/fatemap_data/FM05/fatemapID/stepFourStarcodeShavedReads50.txt\n",
      "Current Sample Adjusted UMI cutoff: 2\n",
      "Current Sample Adjusted UMI cutoff: 2\n",
      "Current Sample Adjusted UMI cutoff: 1\n",
      "Current Sample Adjusted UMI cutoff: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:32<00:00, 155.07it/s]\n",
      "100%|██████████| 5000/5000 [00:31<00:00, 157.81it/s]\n",
      "100%|██████████| 5000/5000 [00:32<00:00, 155.14it/s]\n",
      "100%|██████████| 5000/5000 [00:31<00:00, 156.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Testing on /projects/p31666/zzhang/doublet-bchmk/data/fatemap_data/FM06/fatemapID/stepFourStarcodeShavedReads50.txt\n",
      "Current Sample Adjusted UMI cutoff: 3\n",
      "Current Sample Adjusted UMI cutoff: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:07<00:00, 655.77it/s]\n",
      "100%|██████████| 5000/5000 [00:07<00:00, 672.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Testing on /projects/p31666/zzhang/doublet-bchmk/data/fatemap_data/FM01/fatemapID/stepFourStarcodeShavedReads50.txt\n",
      "Current Sample Adjusted UMI cutoff: 3\n",
      "Current Sample Adjusted UMI cutoff: 3\n",
      "Current Sample Adjusted UMI cutoff: 3\n",
      "Current Sample Adjusted UMI cutoff: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:11<00:00, 417.57it/s]\n",
      "100%|██████████| 5000/5000 [00:11<00:00, 419.21it/s]\n",
      "100%|██████████| 5000/5000 [00:11<00:00, 423.45it/s]\n",
      "100%|██████████| 4621/4621 [00:11<00:00, 415.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Testing on /projects/p31666/zzhang/doublet-bchmk/data/fatemap_data/FM02/fatemapID/stepFourStarcodeShavedReads50.txt\n",
      "Current Sample Adjusted UMI cutoff: 12\n",
      "Current Sample Adjusted UMI cutoff: 15\n",
      "Current Sample Adjusted UMI cutoff: 9\n",
      "Current Sample Adjusted UMI cutoff: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:14<00:00, 355.86it/s]\n",
      "100%|██████████| 5000/5000 [00:14<00:00, 352.33it/s]\n",
      "100%|██████████| 5000/5000 [00:14<00:00, 349.53it/s]\n",
      "100%|██████████| 5000/5000 [00:14<00:00, 349.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Testing on /projects/p31666/zzhang/doublet-bchmk/data/fatemap_data/FM03/fatemapID/stepFourStarcodeShavedReads50.txt\n",
      "Current Sample Adjusted UMI cutoff: 12\n",
      "Current Sample Adjusted UMI cutoff: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:05<00:00, 865.94it/s]\n",
      "100%|██████████| 4713/4713 [00:05<00:00, 880.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Testing on /projects/p31666/zzhang/doublet-bchmk/data/fatemap_data/FM08/fatemapID/stepFourStarcodeShavedReads50.txt\n",
      "Current Sample Adjusted UMI cutoff: 5\n",
      "Current Sample Adjusted UMI cutoff: 11\n",
      "Current Sample Adjusted UMI cutoff: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1415/1415 [00:01<00:00, 1158.58it/s]\n",
      "100%|██████████| 3221/3221 [00:02<00:00, 1196.76it/s]\n",
      "100%|██████████| 466/466 [00:00<00:00, 1221.86it/s]\n"
     ]
    }
   ],
   "source": [
    "all_fatemap_read_files = grab_input_files(data_root, pattern)\n",
    "\n",
    "for cur_fatemap_read_file in all_fatemap_read_files:\n",
    "    print(\"INFO: Testing on {}\".format(cur_fatemap_read_file))\n",
    "    df = pd.read_csv(cur_fatemap_read_file, sep='\\t')\n",
    "    header = list(df.columns)\n",
    "    if header[-1].lower() == \"sampleNum\".lower():\n",
    "        header[-1] = \"sampleNum\"\n",
    "        df.columns = header\n",
    "    good_data_ls = []\n",
    "    for cur_sample_num in df[\"sampleNum\"].unique():\n",
    "        cur_sample_df = df[df[\"sampleNum\"] == cur_sample_num]\n",
    "        cur_umi_adjusted_cutoff = round(umi_cutoff_ratio * cur_sample_df.shape[0])\n",
    "        print(\"Current Sample Adjusted UMI cutoff: {}\".format(cur_umi_adjusted_cutoff))\n",
    "        cur_freq_df = cur_sample_df.groupby(['cellID', 'BC50StarcodeD8', 'sampleNum']).size().reset_index()\n",
    "        cur_freq_df.columns = ['cellID', \"fatemapID\", 'sampleNum', \"nUMI\"]\n",
    "        cur_good_data = cur_freq_df[cur_freq_df['nUMI'] >= cur_umi_adjusted_cutoff].reset_index(drop=True)\n",
    "        good_data_ls.append(cur_good_data)\n",
    "\n",
    "    good_data = pd.concat(good_data_ls)\n",
    "    good_data = good_data.sort_values(by=[\"sampleNum\", 'cellID', 'fatemapID', 'nUMI']).reset_index(drop=True)\n",
    "\n",
    "    all_samples = good_data['sampleNum'].unique()\n",
    "    cellID2fatemap_dict = {}\n",
    "    cellID2fatemap_count_dict = {}\n",
    "\n",
    "    # initialize the count dictionaries\n",
    "    for i in all_samples:\n",
    "        cellID2fatemap_dict[i] = {}\n",
    "        cellID2fatemap_count_dict[i] = {}\n",
    "\n",
    "    # loop through each row\n",
    "    for index, row in good_data.iterrows():\n",
    "        cur_cellID = row['cellID']\n",
    "        cur_fateID = row['fatemapID']\n",
    "        cur_sample_num = int(row['sampleNum'])\n",
    "\n",
    "        # only look at samples 1 and 2 for now\n",
    "        # if(cur_sample_num not in all_samples):\n",
    "        #     continue\n",
    "        if cur_cellID not in cellID2fatemap_dict[cur_sample_num].keys():\n",
    "            cellID2fatemap_dict[cur_sample_num][cur_cellID] = [cur_fateID]\n",
    "            cellID2fatemap_count_dict[cur_sample_num][cur_cellID] = 1\n",
    "        else:\n",
    "            # only add if the fateID is not present in the dict\n",
    "            if cur_fateID not in cellID2fatemap_dict[cur_sample_num][cur_cellID]:\n",
    "                cellID2fatemap_dict[cur_sample_num][cur_cellID].append(cur_fateID)\n",
    "                cellID2fatemap_count_dict[cur_sample_num][cur_cellID] += 1\n",
    "                \n",
    "#     dataset_dicts[cur_fatemap_read_file][\"cellID2fatemap_dict\"]=cellID2fatemap_dict\n",
    "#     dataset_dicts[cur_fatemap_read_file][\"cellID2fatemap_count_dict\"]=cellID2fatemap_count_dict\n",
    "    \n",
    "    ########################\n",
    "    ######## TEST ##########\n",
    "    ########################\n",
    "    for cur_sample in cellID2fatemap_count_dict.keys():\n",
    "        cur_sample_cellIDs = cellID2fatemap_count_dict[cur_sample].keys()\n",
    "        cellIDs_test = random.sample(cur_sample_cellIDs, min(num_tests, len(cur_sample_cellIDs)))\n",
    "        for cur_cellID in tqdm(cellIDs_test):\n",
    "            cur_cellID_count = cellID2fatemap_count_dict[cur_sample][cur_cellID]\n",
    "            cur_cellID_fatemap = cellID2fatemap_dict[cur_sample][cur_cellID]\n",
    "            cur_df = good_data[(good_data[\"cellID\"]==cur_cellID) & (good_data[\"sampleNum\"]==cur_sample)]\n",
    "            cur_fatemap_count = cur_df.shape[0]\n",
    "            if(cur_cellID_count!=cur_fatemap_count):\n",
    "                break\n",
    "            if(set(cur_df[\"fatemapID\"].values)!=set(cur_cellID_fatemap)):\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test regular singlets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Testing on /projects/p31666/zzhang/doublet-bchmk/data/fatemap_data/FM04/fatemapID/stepFourStarcodeShavedReads50.txt\n",
      "Current Sample 1 Adjusted UMI cutoff: 2\n",
      "Current Sample 2 Adjusted UMI cutoff: 3\n",
      "Total cells: 28077\n",
      "Sample 1 singlet: 2222\n",
      "Sample 2 singlet: 4608\n",
      "Total Singlets: 6830\n",
      "Total Multiplets: 6390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:07<00:00, 635.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Testing on /projects/p31666/zzhang/doublet-bchmk/data/fatemap_data/non_cancer/fatemapID/stepFourStarcodeShavedReads50.txt\n",
      "Current Sample 1 Adjusted UMI cutoff: 4\n",
      "Current Sample 2 Adjusted UMI cutoff: 2\n",
      "Total cells: 44493\n",
      "Sample 1 singlet: 1353\n",
      "Sample 2 singlet: 766\n",
      "Total Singlets: 2119\n",
      "Total Multiplets: 3439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2119/2119 [00:04<00:00, 433.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Testing on /projects/p31666/zzhang/doublet-bchmk/data/fatemap_data/FM05/fatemapID/stepFourStarcodeShavedReads50.txt\n",
      "Current Sample 1 Adjusted UMI cutoff: 2\n",
      "Current Sample 2 Adjusted UMI cutoff: 2\n",
      "Current Sample 3 Adjusted UMI cutoff: 1\n",
      "Current Sample 4 Adjusted UMI cutoff: 1\n",
      "Total cells: 124224\n",
      "Sample 1 singlet: 6216\n",
      "Sample 2 singlet: 6498\n",
      "Sample 3 singlet: 1219\n",
      "Sample 4 singlet: 1911\n",
      "Total Singlets: 15844\n",
      "Total Multiplets: 24263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:29<00:00, 166.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Testing on /projects/p31666/zzhang/doublet-bchmk/data/fatemap_data/FM06/fatemapID/stepFourStarcodeShavedReads50.txt\n",
      "Current Sample 1 Adjusted UMI cutoff: 3\n",
      "Current Sample 2 Adjusted UMI cutoff: 3\n",
      "Total cells: 20044\n",
      "Sample 1 singlet: 6573\n",
      "Sample 2 singlet: 5946\n",
      "Total Singlets: 12519\n",
      "Total Multiplets: 2990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:05<00:00, 847.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Testing on /projects/p31666/zzhang/doublet-bchmk/data/fatemap_data/FM01/fatemapID/stepFourStarcodeShavedReads50.txt\n",
      "Current Sample 1 Adjusted UMI cutoff: 3\n",
      "Current Sample 2 Adjusted UMI cutoff: 3\n",
      "Current Sample 3 Adjusted UMI cutoff: 3\n",
      "Current Sample 4 Adjusted UMI cutoff: 3\n",
      "Total cells: 39207\n",
      "Sample 1 singlet: 4564\n",
      "Sample 2 singlet: 4366\n",
      "Sample 3 singlet: 5441\n",
      "Sample 4 singlet: 2999\n",
      "Total Singlets: 17370\n",
      "Total Multiplets: 8200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:10<00:00, 467.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Testing on /projects/p31666/zzhang/doublet-bchmk/data/fatemap_data/FM02/fatemapID/stepFourStarcodeShavedReads50.txt\n",
      "Current Sample 1 Adjusted UMI cutoff: 12\n",
      "Current Sample 2 Adjusted UMI cutoff: 15\n",
      "Current Sample 3 Adjusted UMI cutoff: 9\n",
      "Current Sample 4 Adjusted UMI cutoff: 8\n",
      "Total cells: 48582\n",
      "Sample 1 singlet: 5562\n",
      "Sample 2 singlet: 6232\n",
      "Sample 3 singlet: 4490\n",
      "Sample 4 singlet: 3439\n",
      "Total Singlets: 19723\n",
      "Total Multiplets: 8727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:12<00:00, 390.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Testing on /projects/p31666/zzhang/doublet-bchmk/data/fatemap_data/FM03/fatemapID/stepFourStarcodeShavedReads50.txt\n",
      "Current Sample 1 Adjusted UMI cutoff: 12\n",
      "Current Sample 2 Adjusted UMI cutoff: 12\n",
      "Total cells: 13397\n",
      "Sample 1 singlet: 4415\n",
      "Sample 2 singlet: 3762\n",
      "Total Singlets: 8177\n",
      "Total Multiplets: 1930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:04<00:00, 1087.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Testing on /projects/p31666/zzhang/doublet-bchmk/data/fatemap_data/FM08/fatemapID/stepFourStarcodeShavedReads50.txt\n",
      "Current Sample 1 Adjusted UMI cutoff: 5\n",
      "Current Sample 2 Adjusted UMI cutoff: 11\n",
      "Current Sample 3 Adjusted UMI cutoff: 0\n",
      "Total cells: 7020\n",
      "Sample 1 singlet: 968\n",
      "Sample 2 singlet: 2548\n",
      "Sample 3 singlet: 234\n",
      "Total Singlets: 3750\n",
      "Total Multiplets: 1348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3750/3750 [00:02<00:00, 1663.39it/s]\n"
     ]
    }
   ],
   "source": [
    "all_fatemap_read_files = grab_input_files(data_root, pattern)\n",
    "\n",
    "dataset_dicts={}\n",
    "def get_multilane_barcodes(good_data):\n",
    "    multilane_barcodes = []\n",
    "    for cur_barcode in good_data[\"cellID\"].unique():\n",
    "        cur_df = good_data[good_data[\"cellID\"] == cur_barcode]\n",
    "        if (len(cur_df[\"sampleNum\"].unique()) > 1):\n",
    "            multilane_barcodes.append(cur_barcode)\n",
    "    return multilane_barcodes\n",
    "\n",
    "for cur_fatemap_read_file in all_fatemap_read_files:\n",
    "    print(\"INFO: Testing on {}\".format(cur_fatemap_read_file))\n",
    "    df = pd.read_csv(cur_fatemap_read_file, sep='\\t')\n",
    "    header = list(df.columns)\n",
    "    if header[-1].lower() == \"sampleNum\".lower():\n",
    "        header[-1] = \"sampleNum\"\n",
    "        df.columns = header\n",
    "    good_data_ls = []\n",
    "    for cur_sample_num in df[\"sampleNum\"].unique():\n",
    "        cur_sample_df = df[df[\"sampleNum\"] == cur_sample_num]\n",
    "        cur_umi_adjusted_cutoff = round(umi_cutoff_ratio * cur_sample_df.shape[0])\n",
    "        print(\"Current Sample {} Adjusted UMI cutoff: {}\".format(cur_sample_num, cur_umi_adjusted_cutoff))\n",
    "        cur_freq_df = cur_sample_df.groupby(['cellID', 'BC50StarcodeD8', 'sampleNum']).size().reset_index()\n",
    "        cur_freq_df.columns = ['cellID', \"fatemapID\", 'sampleNum', \"nUMI\"]\n",
    "        cur_good_data = cur_freq_df[cur_freq_df['nUMI'] >= cur_umi_adjusted_cutoff].reset_index(drop=True)\n",
    "        good_data_ls.append(cur_good_data)\n",
    "\n",
    "    good_data = pd.concat(good_data_ls)\n",
    "    good_data = good_data.sort_values(by=[\"sampleNum\", 'cellID', 'fatemapID', 'nUMI']).reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    blacklist_barcodes = get_multilane_barcodes(good_data)\n",
    "    \n",
    "    all_samples = good_data['sampleNum'].unique()\n",
    "    cellID2fatemap_dict = {}\n",
    "    cellID2fatemap_count_dict = {}\n",
    "\n",
    "    # initialize the count dictionaries\n",
    "    for i in all_samples:\n",
    "        cellID2fatemap_dict[i] = {}\n",
    "        cellID2fatemap_count_dict[i] = {}\n",
    "\n",
    "    # loop through each row\n",
    "    for index, row in good_data.iterrows():\n",
    "        cur_cellID = row['cellID']\n",
    "        cur_fateID = row['fatemapID']\n",
    "        cur_sample_num = int(row['sampleNum'])\n",
    "\n",
    "        # only look at samples 1 and 2 for now\n",
    "        # if(cur_sample_num not in all_samples):\n",
    "        #     continue\n",
    "        if cur_cellID not in cellID2fatemap_dict[cur_sample_num].keys():\n",
    "            cellID2fatemap_dict[cur_sample_num][cur_cellID] = [cur_fateID]\n",
    "            cellID2fatemap_count_dict[cur_sample_num][cur_cellID] = 1\n",
    "        else:\n",
    "            # only add if the fateID is not present in the dict\n",
    "            if cur_fateID not in cellID2fatemap_dict[cur_sample_num][cur_cellID]:\n",
    "                cellID2fatemap_dict[cur_sample_num][cur_cellID].append(cur_fateID)\n",
    "                cellID2fatemap_count_dict[cur_sample_num][cur_cellID] += 1\n",
    "\n",
    "    singlets = []\n",
    "    multiplets = []\n",
    "    print(\"Total cells: {}\".format(len(good_data[\"cellID\"])))\n",
    "    for sample_id, cur_dict in cellID2fatemap_count_dict.items():\n",
    "        cur_sample_count = 0\n",
    "        for barcode, count in cur_dict.items():\n",
    "#             if the barcode is present in more than one lane, remove it\n",
    "            if barcode in blacklist_barcodes:\n",
    "                continue\n",
    "            if count == 1:\n",
    "                cur_sample_count += 1\n",
    "                singlets.append(barcode)\n",
    "            else:\n",
    "                multiplets.append(barcode)\n",
    "        print(\"Sample {} singlet: {}\".format(sample_id, cur_sample_count))\n",
    "    print(\"Total Singlets: {}\\nTotal Multiplets: {}\".format(len(singlets), len(multiplets)))\n",
    "    \n",
    "    ########################\n",
    "    ######## TEST ##########\n",
    "    ########################\n",
    "    cellIDs_test = random.sample(singlets, min(num_tests, len(singlets)))\n",
    "    for cur_id in tqdm(cellIDs_test):\n",
    "        cur_df = good_data[(good_data[\"cellID\"]==cur_id)]\n",
    "        cur_cellID_count = cur_df.shape[0]\n",
    "        if(cur_cellID_count!=1):\n",
    "            break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test multilane singlets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Testing on /projects/p31666/zzhang/doublet-bchmk/data/fatemap_data/FM04/fatemapID/stepFourStarcodeShavedReads50.txt\n",
      "Current Sample 1 Adjusted UMI cutoff: 2\n",
      "Current Sample 2 Adjusted UMI cutoff: 3\n",
      "Total cells: 28077\n",
      "Sample 1 singlet: 2222\n",
      "Sample 2 singlet: 4608\n",
      "Total Singlets: 6830\n",
      "Total Multiplets: 6390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2935/2935 [00:10<00:00, 286.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Testing on /projects/p31666/zzhang/doublet-bchmk/data/fatemap_data/non_cancer/fatemapID/stepFourStarcodeShavedReads50.txt\n",
      "Current Sample 1 Adjusted UMI cutoff: 4\n",
      "Current Sample 2 Adjusted UMI cutoff: 2\n",
      "Total cells: 44493\n",
      "Sample 1 singlet: 1353\n",
      "Sample 2 singlet: 766\n",
      "Total Singlets: 2119\n",
      "Total Multiplets: 3439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 271/271 [00:01<00:00, 269.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Testing on /projects/p31666/zzhang/doublet-bchmk/data/fatemap_data/FM05/fatemapID/stepFourStarcodeShavedReads50.txt\n",
      "Current Sample 1 Adjusted UMI cutoff: 2\n",
      "Current Sample 2 Adjusted UMI cutoff: 2\n",
      "Current Sample 3 Adjusted UMI cutoff: 1\n",
      "Current Sample 4 Adjusted UMI cutoff: 1\n",
      "Total cells: 124224\n",
      "Sample 1 singlet: 6216\n",
      "Sample 2 singlet: 6498\n",
      "Sample 3 singlet: 1219\n",
      "Sample 4 singlet: 1911\n",
      "Total Singlets: 15844\n",
      "Total Multiplets: 24263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 671/671 [00:05<00:00, 116.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Testing on /projects/p31666/zzhang/doublet-bchmk/data/fatemap_data/FM06/fatemapID/stepFourStarcodeShavedReads50.txt\n",
      "Current Sample 1 Adjusted UMI cutoff: 3\n",
      "Current Sample 2 Adjusted UMI cutoff: 3\n",
      "Total cells: 20044\n",
      "Sample 1 singlet: 6573\n",
      "Sample 2 singlet: 5946\n",
      "Total Singlets: 12519\n",
      "Total Multiplets: 2990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 506/506 [00:01<00:00, 427.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Testing on /projects/p31666/zzhang/doublet-bchmk/data/fatemap_data/FM01/fatemapID/stepFourStarcodeShavedReads50.txt\n",
      "Current Sample 1 Adjusted UMI cutoff: 3\n",
      "Current Sample 2 Adjusted UMI cutoff: 3\n",
      "Current Sample 3 Adjusted UMI cutoff: 3\n",
      "Current Sample 4 Adjusted UMI cutoff: 3\n",
      "Total cells: 39207\n",
      "Sample 1 singlet: 4564\n",
      "Sample 2 singlet: 4366\n",
      "Sample 3 singlet: 5441\n",
      "Sample 4 singlet: 2999\n",
      "Total Singlets: 17370\n",
      "Total Multiplets: 8200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2678/2678 [00:10<00:00, 260.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Testing on /projects/p31666/zzhang/doublet-bchmk/data/fatemap_data/FM02/fatemapID/stepFourStarcodeShavedReads50.txt\n",
      "Current Sample 1 Adjusted UMI cutoff: 12\n",
      "Current Sample 2 Adjusted UMI cutoff: 15\n",
      "Current Sample 3 Adjusted UMI cutoff: 9\n",
      "Current Sample 4 Adjusted UMI cutoff: 8\n",
      "Total cells: 48582\n",
      "Sample 1 singlet: 5562\n",
      "Sample 2 singlet: 6232\n",
      "Sample 3 singlet: 4490\n",
      "Sample 4 singlet: 3439\n",
      "Total Singlets: 19723\n",
      "Total Multiplets: 8727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3875/3875 [00:26<00:00, 148.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Testing on /projects/p31666/zzhang/doublet-bchmk/data/fatemap_data/FM03/fatemapID/stepFourStarcodeShavedReads50.txt\n",
      "Current Sample 1 Adjusted UMI cutoff: 12\n",
      "Current Sample 2 Adjusted UMI cutoff: 12\n",
      "Total cells: 13397\n",
      "Sample 1 singlet: 4415\n",
      "Sample 2 singlet: 3762\n",
      "Total Singlets: 8177\n",
      "Total Multiplets: 1930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 664/664 [00:01<00:00, 461.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Testing on /projects/p31666/zzhang/doublet-bchmk/data/fatemap_data/FM08/fatemapID/stepFourStarcodeShavedReads50.txt\n",
      "Current Sample 1 Adjusted UMI cutoff: 5\n",
      "Current Sample 2 Adjusted UMI cutoff: 11\n",
      "Current Sample 3 Adjusted UMI cutoff: 0\n",
      "Total cells: 7020\n",
      "Sample 1 singlet: 968\n",
      "Sample 2 singlet: 2548\n",
      "Sample 3 singlet: 234\n",
      "Total Singlets: 3750\n",
      "Total Multiplets: 1348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1050/1050 [00:27<00:00, 38.37it/s] \n"
     ]
    }
   ],
   "source": [
    "all_fatemap_read_files = grab_input_files(data_root, pattern)\n",
    "\n",
    "dataset_dicts={}\n",
    "def get_multilane_barcodes(good_data):\n",
    "    multilane_barcodes = []\n",
    "    for cur_barcode in good_data[\"cellID\"].unique():\n",
    "        cur_df = good_data[good_data[\"cellID\"] == cur_barcode]\n",
    "        if (len(cur_df[\"sampleNum\"].unique()) > 1):\n",
    "            multilane_barcodes.append(cur_barcode)\n",
    "    return multilane_barcodes\n",
    "\n",
    "for cur_fatemap_read_file in all_fatemap_read_files:\n",
    "    print(\"INFO: Testing on {}\".format(cur_fatemap_read_file))\n",
    "    df = pd.read_csv(cur_fatemap_read_file, sep='\\t')\n",
    "    header = list(df.columns)\n",
    "    if header[-1].lower() == \"sampleNum\".lower():\n",
    "        header[-1] = \"sampleNum\"\n",
    "        df.columns = header\n",
    "    good_data_ls = []\n",
    "    for cur_sample_num in df[\"sampleNum\"].unique():\n",
    "        cur_sample_df = df[df[\"sampleNum\"] == cur_sample_num]\n",
    "        cur_umi_adjusted_cutoff = round(umi_cutoff_ratio * cur_sample_df.shape[0])\n",
    "        print(\"Current Sample {} Adjusted UMI cutoff: {}\".format(cur_sample_num, cur_umi_adjusted_cutoff))\n",
    "        cur_freq_df = cur_sample_df.groupby(['cellID', 'BC50StarcodeD8', 'sampleNum']).size().reset_index()\n",
    "        cur_freq_df.columns = ['cellID', \"fatemapID\", 'sampleNum', \"nUMI\"]\n",
    "        cur_good_data = cur_freq_df[cur_freq_df['nUMI'] >= cur_umi_adjusted_cutoff].reset_index(drop=True)\n",
    "        good_data_ls.append(cur_good_data)\n",
    "\n",
    "    good_data = pd.concat(good_data_ls)\n",
    "    good_data = good_data.sort_values(by=[\"sampleNum\", 'cellID', 'fatemapID', 'nUMI']).reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    blacklist_barcodes = get_multilane_barcodes(good_data)\n",
    "    \n",
    "    all_samples = good_data['sampleNum'].unique()\n",
    "    cellID2fatemap_dict = {}\n",
    "    cellID2fatemap_count_dict = {}\n",
    "\n",
    "    # initialize the count dictionaries\n",
    "    for i in all_samples:\n",
    "        cellID2fatemap_dict[i] = {}\n",
    "        cellID2fatemap_count_dict[i] = {}\n",
    "\n",
    "    # loop through each row\n",
    "    for index, row in good_data.iterrows():\n",
    "        cur_cellID = row['cellID']\n",
    "        cur_fateID = row['fatemapID']\n",
    "        cur_sample_num = int(row['sampleNum'])\n",
    "\n",
    "        # only look at samples 1 and 2 for now\n",
    "        # if(cur_sample_num not in all_samples):\n",
    "        #     continue\n",
    "        if cur_cellID not in cellID2fatemap_dict[cur_sample_num].keys():\n",
    "            cellID2fatemap_dict[cur_sample_num][cur_cellID] = [cur_fateID]\n",
    "            cellID2fatemap_count_dict[cur_sample_num][cur_cellID] = 1\n",
    "        else:\n",
    "            # only add if the fateID is not present in the dict\n",
    "            if cur_fateID not in cellID2fatemap_dict[cur_sample_num][cur_cellID]:\n",
    "                cellID2fatemap_dict[cur_sample_num][cur_cellID].append(cur_fateID)\n",
    "                cellID2fatemap_count_dict[cur_sample_num][cur_cellID] += 1\n",
    "\n",
    "    singlets = []\n",
    "    multiplets = []\n",
    "    print(\"Total cells: {}\".format(len(good_data[\"cellID\"])))\n",
    "    for sample_id, cur_dict in cellID2fatemap_count_dict.items():\n",
    "        cur_sample_count = 0\n",
    "        for barcode, count in cur_dict.items():\n",
    "#             if the barcode is present in more than one lane, remove it\n",
    "            if barcode in blacklist_barcodes:\n",
    "                continue\n",
    "            if count == 1:\n",
    "                cur_sample_count += 1\n",
    "                singlets.append(barcode)\n",
    "            else:\n",
    "                multiplets.append(barcode)\n",
    "        print(\"Sample {} singlet: {}\".format(sample_id, cur_sample_count))\n",
    "    print(\"Total Singlets: {}\\nTotal Multiplets: {}\".format(len(singlets), len(multiplets)))\n",
    "    \n",
    "    fatemapID_dict = {}\n",
    "    fatemapID_count_dict = {}\n",
    "\n",
    "    for cur_multiplet in multiplets:\n",
    "        cur_df = good_data[good_data[\"cellID\"] == cur_multiplet]\n",
    "        # only consider when more than 1 fate barcode appears\n",
    "        n_unique_fatemap_barcodes = len(cur_df[\"fatemapID\"].unique())\n",
    "        if n_unique_fatemap_barcodes < 2:\n",
    "            continue\n",
    "        # create unique key for each fatemap barcode ID\n",
    "        fatemapID_combo = \"_\".join(sorted(cur_df[\"fatemapID\"].unique()))\n",
    "        if fatemapID_combo not in fatemapID_dict:\n",
    "            fatemapID_dict[fatemapID_combo] = [cur_multiplet]\n",
    "            fatemapID_count_dict[fatemapID_combo] = 1\n",
    "        else:\n",
    "            fatemapID_dict[fatemapID_combo].append(cur_multiplet)\n",
    "            fatemapID_count_dict[fatemapID_combo] += 1\n",
    "\n",
    "    two_barcode_singlets_count = 0\n",
    "    two_barcode_singlets = []\n",
    "    for key, value in fatemapID_count_dict.items():\n",
    "        if value >= 2:\n",
    "            two_barcode_singlets_count += value\n",
    "            two_barcode_singlets.extend(fatemapID_dict[key])\n",
    "            if fatemapID_dict[key] in two_barcode_singlets:\n",
    "                print(fatemapID_dict[key])\n",
    "    ########################\n",
    "    ######## TEST ##########\n",
    "    ########################\n",
    "    for cur_two_barcode_singlet in tqdm(two_barcode_singlets):\n",
    "        cur_df = good_data[good_data[\"cellID\"] == cur_two_barcode_singlet]\n",
    "        cur_fatemap_barcodes = \"_\".join(sorted(cur_df[\"fatemapID\"].unique()))\n",
    "        cur_recovered_singlets = fatemapID_dict[cur_fatemap_barcodes]\n",
    "        cur_recovered_df = good_data[good_data[\"cellID\"].isin(fatemapID_dict[fatemapID_combo])]\n",
    "        for cur_recovered_singlet in cur_recovered_df[\"cellID\"].unique():\n",
    "            cur_recovered_df_cur_singlet = cur_recovered_df[cur_recovered_df[\"cellID\"]==cur_recovered_singlet]\n",
    "            cur_recovered_singlet_fatemap_combo = \"_\".join(sorted(cur_recovered_df_cur_singlet[\"fatemapID\"].unique()))\n",
    "            if(cur_recovered_singlet_fatemap_combo!=cur_fatemap_barcodes):\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test UMI singlets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Raw data counts\n",
      "2    404787\n",
      "1    313223\n",
      "Name: sampleNum, dtype: int64\n",
      "Current Sample Adjusted UMI cutoff: 2\n",
      "Current Sample Adjusted UMI cutoff: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28077/28077 [00:01<00:00, 27089.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cells: 28077\n",
      "Sample 1 singlet: 2222\n",
      "Sample 2 singlet: 4608\n",
      "Total Singlets: 6830\n",
      "Total Multiplets: 6390\n",
      "All singlets identified are unique? True\n",
      "Total Singlets: 9766\n",
      "Total Multiplets: 3454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Benchmarking: 100%|██████████| 1/1 [00:00<00:00, 330.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Raw data counts\n",
      "1    475505\n",
      "2    315727\n",
      "Name: sampleNum, dtype: int64\n",
      "Current Sample Adjusted UMI cutoff: 4\n",
      "Current Sample Adjusted UMI cutoff: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44493/44493 [00:01<00:00, 26561.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cells: 44493\n",
      "Sample 1 singlet: 1353\n",
      "Sample 2 singlet: 766\n",
      "Total Singlets: 2119\n",
      "Total Multiplets: 3439\n",
      "All singlets identified are unique? True\n",
      "Total Singlets: 2391\n",
      "Total Multiplets: 3167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Benchmarking: 100%|██████████| 1/1 [00:00<00:00, 383.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Raw data counts\n",
      "2    271108\n",
      "1    228579\n",
      "3    147593\n",
      "4     96490\n",
      "Name: sampleNum, dtype: int64\n",
      "Current Sample Adjusted UMI cutoff: 2\n",
      "Current Sample Adjusted UMI cutoff: 2\n",
      "Current Sample Adjusted UMI cutoff: 1\n",
      "Current Sample Adjusted UMI cutoff: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 124224/124224 [00:05<00:00, 24458.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cells: 124224\n",
      "Sample 1 singlet: 6216\n",
      "Sample 2 singlet: 6498\n",
      "Sample 3 singlet: 1219\n",
      "Sample 4 singlet: 1911\n",
      "Total Singlets: 15844\n",
      "Total Multiplets: 24263\n",
      "All singlets identified are unique? True\n",
      "Total Singlets: 16516\n",
      "Total Multiplets: 23591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Benchmarking: 100%|██████████| 1/1 [00:00<00:00, 150.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Raw data counts\n",
      "1    418229\n",
      "2    395456\n",
      "Name: sampleNum, dtype: int64\n",
      "Current Sample Adjusted UMI cutoff: 3\n",
      "Current Sample Adjusted UMI cutoff: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20044/20044 [00:00<00:00, 27188.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cells: 20044\n",
      "Sample 1 singlet: 6573\n",
      "Sample 2 singlet: 5946\n",
      "Total Singlets: 12519\n",
      "Total Multiplets: 2990\n",
      "All singlets identified are unique? True\n",
      "Total Singlets: 13026\n",
      "Total Multiplets: 2483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Benchmarking: 100%|██████████| 1/1 [00:00<00:00, 575.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Raw data counts\n",
      "1    442323\n",
      "3    381348\n",
      "2    377422\n",
      "4    343348\n",
      "Name: sampleNum, dtype: int64\n",
      "Current Sample Adjusted UMI cutoff: 3\n",
      "Current Sample Adjusted UMI cutoff: 3\n",
      "Current Sample Adjusted UMI cutoff: 3\n",
      "Current Sample Adjusted UMI cutoff: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39207/39207 [00:01<00:00, 26770.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cells: 39207\n",
      "Sample 1 singlet: 4564\n",
      "Sample 2 singlet: 4366\n",
      "Sample 3 singlet: 5441\n",
      "Sample 4 singlet: 2999\n",
      "Total Singlets: 17370\n",
      "Total Multiplets: 8200\n",
      "All singlets identified are unique? True\n",
      "Total Singlets: 20049\n",
      "Total Multiplets: 5521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Benchmarking: 100%|██████████| 1/1 [00:00<00:00, 416.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Raw data counts\n",
      "2    2033409\n",
      "1    1600666\n",
      "3    1223760\n",
      "4    1008678\n",
      "Name: sampleNum, dtype: int64\n",
      "Current Sample Adjusted UMI cutoff: 12\n",
      "Current Sample Adjusted UMI cutoff: 15\n",
      "Current Sample Adjusted UMI cutoff: 9\n",
      "Current Sample Adjusted UMI cutoff: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48582/48582 [00:01<00:00, 24938.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cells: 48582\n",
      "Sample 1 singlet: 5562\n",
      "Sample 2 singlet: 6232\n",
      "Sample 3 singlet: 4490\n",
      "Sample 4 singlet: 3439\n",
      "Total Singlets: 19723\n",
      "Total Multiplets: 8727\n",
      "All singlets identified are unique? True\n",
      "Total Singlets: 23599\n",
      "Total Multiplets: 4851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Benchmarking: 100%|██████████| 1/1 [00:00<00:00, 320.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Raw data counts\n",
      "2    1659871\n",
      "1    1620309\n",
      "Name: sampleNum, dtype: int64\n",
      "Current Sample Adjusted UMI cutoff: 12\n",
      "Current Sample Adjusted UMI cutoff: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13397/13397 [00:00<00:00, 26829.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cells: 13397\n",
      "Sample 1 singlet: 4415\n",
      "Sample 2 singlet: 3762\n",
      "Total Singlets: 8177\n",
      "Total Multiplets: 1930\n",
      "All singlets identified are unique? True\n",
      "Total Singlets: 8841\n",
      "Total Multiplets: 1266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Benchmarking: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Raw data counts\n",
      "2    1454787\n",
      "1     614619\n",
      "3      11716\n",
      "Name: sampleNum, dtype: int64\n",
      "Current Sample Adjusted UMI cutoff: 5\n",
      "Current Sample Adjusted UMI cutoff: 11\n",
      "Current Sample Adjusted UMI cutoff: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7020/7020 [00:00<00:00, 26102.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cells: 7020\n",
      "Sample 1 singlet: 968\n",
      "Sample 2 singlet: 2548\n",
      "Sample 3 singlet: 234\n",
      "Total Singlets: 3750\n",
      "Total Multiplets: 1348\n",
      "All singlets identified are unique? True\n",
      "Total Singlets: 4801\n",
      "Total Multiplets: 297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Benchmarking: 100%|██████████| 1/1 [00:00<00:00, 1172.25it/s]\n"
     ]
    }
   ],
   "source": [
    "singlets_stat_ls=[]\n",
    "\n",
    "for cur_fatemap_read_file in all_fatemap_read_files:\n",
    "    cur_singlet_stats = []\n",
    "    df = pd.read_csv(cur_fatemap_read_file, sep='\\t')\n",
    "    \n",
    "    # some sampleNum is written as SampleNum\n",
    "    # force conversion\n",
    "    header = list(df.columns)\n",
    "    if header[-1].lower() == \"sampleNum\".lower():\n",
    "        header[-1] = \"sampleNum\"\n",
    "        df.columns = header\n",
    "\n",
    "    df_sum = df['sampleNum'].value_counts()\n",
    "    all_samples = df['sampleNum'].unique()\n",
    "    print(\"INFO: Raw data counts\")\n",
    "    print(df_sum)\n",
    "\n",
    "    # adjust UMI cutoff based on reads\n",
    "    # drop cells that do not pass UMI cutoff\n",
    "    good_data_ls = []\n",
    "    for cur_sample_num in df[\"sampleNum\"].unique():\n",
    "        cur_sample_df = df[df[\"sampleNum\"] == cur_sample_num]\n",
    "        cur_umi_adjusted_cutoff = round(umi_cutoff_ratio * cur_sample_df.shape[0])\n",
    "        print(\"Current Sample Adjusted UMI cutoff: {}\".format(cur_umi_adjusted_cutoff))\n",
    "        cur_freq_df = cur_sample_df.groupby(['cellID', 'BC50StarcodeD8', 'sampleNum']).size().reset_index()\n",
    "        cur_freq_df.columns = ['cellID', \"fatemapID\", 'sampleNum', \"nUMI\"]\n",
    "        cur_good_data = cur_freq_df[cur_freq_df['nUMI'] >= cur_umi_adjusted_cutoff].reset_index(drop=True)\n",
    "        good_data_ls.append(cur_good_data)\n",
    "    good_data = pd.concat(good_data_ls)\n",
    "    good_data = good_data.sort_values(by=[\"sampleNum\", 'cellID', 'fatemapID', 'nUMI']).reset_index(drop=True)\n",
    "\n",
    "    # get fatemap barcode count for each cellID\n",
    "    cellID2fatemap_dict, cellID2fatemap_count_dict = \\\n",
    "        generate_fatemap_barcode_counts_for_cellID(good_data)\n",
    "\n",
    "    # get multilane barcodes\n",
    "    multilane_barcodes = get_multilane_barcodes(good_data)\n",
    "\n",
    "    # get first round of results\n",
    "    singlets, multiplets = define_singlets_and_multiplets_based_on_fatemapID_counts(cellID2fatemap_count_dict,\n",
    "                                                                                    good_data,\n",
    "                                                                                    multilane_barcodes)\n",
    "    cur_singlet_stats.append(len(singlets))\n",
    "    # salvage false multiplets\n",
    "    fatemapID_dict, fatemapID_count_dict = generate_fatemapID_combo(multiplets, \\\n",
    "                                                                    good_data)\n",
    "\n",
    "    two_barcode_singlets = extract_two_fatemapID_singlets(fatemapID_dict, \\\n",
    "                                                          fatemapID_count_dict)\n",
    "    \n",
    "    cur_singlet_stats.append(len(two_barcode_singlets))\n",
    "    # update singlets and multiplets\n",
    "    singlets_step2 = list(set(singlets).union(set(two_barcode_singlets)))\n",
    "    multiplets_step2 = list(set(multiplets).difference(set(two_barcode_singlets)))\n",
    "    \n",
    "    \n",
    "    UMI_thres_singlets = []\n",
    "    for cur_multiplet in multiplets_step2:\n",
    "        cur_df = good_data[good_data[\"cellID\"] == cur_multiplet]\n",
    "        cur_UMI_counts = cur_df['nUMI'].values\n",
    "        cur_median_UMI = np.median(cur_UMI_counts)\n",
    "        if (np.max(cur_UMI_counts) - cur_median_UMI) > umi_diff_threshold:\n",
    "            # check if there is more than 1 dominant\n",
    "            dominant_count = 0\n",
    "            for cur_UMI in cur_UMI_counts:\n",
    "                cur_diff = cur_UMI - cur_median_UMI\n",
    "                if cur_diff > umi_diff_threshold or cur_UMI > dominant_threshold:\n",
    "                    dominant_count += 1\n",
    "\n",
    "            if dominant_count == 1:\n",
    "                UMI_thres_singlets.append(cur_multiplet)\n",
    "                break\n",
    "    cur_singlet_stats.append(len(UMI_thres_singlets))\n",
    "    singlets_step3 = list(set(singlets_step2).union(set(UMI_thres_singlets)))\n",
    "    multiplets_step3 = list(set(multiplets_step2).difference(set(UMI_thres_singlets)))\n",
    "    print(\"Total Singlets: {}\\nTotal Multiplets: {}\".format(len(singlets_step3), len(multiplets_step3)))\n",
    "    cur_singlet_stats.append(len(singlets_step3))\n",
    "    cur_singlet_stats.append(len(multiplets_step3))\n",
    "    singlets_stat_ls.append(cur_singlet_stats)\n",
    "    ########################\n",
    "    ######## TEST ##########\n",
    "    ########################\n",
    "    \n",
    "    for cur_umi_thres_singlet in tqdm(UMI_thres_singlets, desc=\"Benchmarking\"):\n",
    "        cur_df = good_data[good_data[\"cellID\"] == cur_umi_thres_singlet]\n",
    "        cur_UMIs = cur_df['nUMI'].values\n",
    "        cur_median = np.median(cur_UMIs)\n",
    "        cur_dominant_umi_num = sum(cur_UMIs-dominant_threshold>0)\n",
    "        if(cur_dominant_umi_num!=1):\n",
    "            break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "singlets_stat_df = pd.DataFrame(cur_singlet_stats).T\n",
    "singlets_stat_df.columns = [\"single_fatemap_barcode_singlets\", \"multi_fatemap_barcode_singlets\", \\\n",
    "                           \"dominant_umi_barcode_singlets\", \"total_singlets\", \"total_undetermined\"]\n",
    "singlets_stat_df[\"total_cells\"]=singlets_stat_df[\"total_singlets\"]+singlets_stat_df[\"total_undetermined\"]\n",
    "singlets_stat_df[\"dataset\"] = cur_fatemap_read_file.split(\"/\")[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>single_fatemap_barcode_singlets</th>\n",
       "      <th>multi_fatemap_barcode_singlets</th>\n",
       "      <th>dominant_umi_barcode_singlets</th>\n",
       "      <th>total_singlets</th>\n",
       "      <th>total_undetermined</th>\n",
       "      <th>total_cells</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3750</td>\n",
       "      <td>1050</td>\n",
       "      <td>1</td>\n",
       "      <td>4801</td>\n",
       "      <td>297</td>\n",
       "      <td>5098</td>\n",
       "      <td>FM08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   single_fatemap_barcode_singlets  multi_fatemap_barcode_singlets  \\\n",
       "0                             3750                            1050   \n",
       "\n",
       "   dominant_umi_barcode_singlets  total_singlets  total_undetermined  \\\n",
       "0                              1            4801                 297   \n",
       "\n",
       "   total_cells dataset  \n",
       "0         5098    FM08  "
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "singlets_stat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FM08'"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_fatemap_read_file.split(\"/\")[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(cur_UMIs-umi_diff_threshold>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "doublet-bchmk",
   "language": "python",
   "name": "doublet-bchmk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
